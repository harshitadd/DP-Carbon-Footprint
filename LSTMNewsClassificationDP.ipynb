{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTMNewsClassificationDP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPzyY5hG6v2t2c1Vkm5MHef",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshitadd/DP-NLP/blob/main/LSTMNewsClassificationDP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10DXTdvxj5ZQ"
      },
      "source": [
        "!pip install opacus[dev] --quiet\n",
        "!pip install transformers --quiet"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_owdx2pklf5"
      },
      "source": [
        "import zipfile\n",
        "import urllib.request\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "from pathlib import Path\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from opacus.utils.uniform_sampler import UniformWithReplacementSampler\n",
        "from opacus import PrivacyEngine\n",
        "from torch.utils.data import TensorDataset\n",
        "from transformers.data.processors.utils import InputExample\n",
        "from transformers.data.processors.glue import glue_convert_examples_to_features"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvd-mlWikysj"
      },
      "source": [
        "DATA_DIR = \"/content/\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pUsYekVkzXg",
        "outputId": "9b4f75b0-0ddc-4875-cb4c-d86e97c08529"
      },
      "source": [
        "def download_and_extract(data_dir):\n",
        "    print(\"Extracting Train zip...\")\n",
        "    filename = \"train.csv.zip\"\n",
        "    with zipfile.ZipFile(filename) as zip_ref:\n",
        "        zip_ref.extractall(data_dir)\n",
        "    os.remove(filename)\n",
        "    print(\"Completed!\")\n",
        "\n",
        "    print(\"Extracting Test zip...\")\n",
        "    filename = \"test.csv.zip\"\n",
        "    with zipfile.ZipFile(filename) as zip_ref:\n",
        "        zip_ref.extractall(data_dir)\n",
        "    os.remove(filename)\n",
        "    print(\"Completed!\")\n",
        "\n",
        "download_and_extract(DATA_DIR)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting Train zip...\n",
            "Completed!\n",
            "Extracting Test zip...\n",
            "Completed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4Bu52Cgk1fk"
      },
      "source": [
        "train_path =  '/content/train.csv'\n",
        "dev_path = '/content/test.csv'\n",
        "\n",
        "df_train = pd.read_csv(train_path)[:2000]\n",
        "df_test = pd.read_csv(dev_path)[:400]\n",
        "df_train = df_train.drop('Title', axis = 1)\n",
        "df_test = df_test.drop('Title', axis = 1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKAW1TLdRXX6"
      },
      "source": [
        "df = pd.concat([df_train, df_test])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwJm9ozelyFH"
      },
      "source": [
        "class CharByteEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.start_token = \"<s>\"\n",
        "        self.end_token = \"</s>\"\n",
        "        self.pad_token = \"<pad>\"\n",
        "        self.start_idx = 256\n",
        "        self.end_idx = 257\n",
        "        self.pad_idx = 258\n",
        "\n",
        "    def forward(self, s: str, pad_to=0) -> torch.LongTensor:\n",
        "\n",
        "        encoded = s.encode()\n",
        "        n_pad = pad_to - len(encoded) if pad_to > len(encoded) else 0\n",
        "        return torch.LongTensor(\n",
        "            [self.start_idx]\n",
        "            + [c for c in encoded]  # noqa\n",
        "            + [self.end_idx]\n",
        "            + [self.pad_idx for _ in range(n_pad)]\n",
        "        )\n",
        "\n",
        "    def decode(self, char_ids_tensor: torch.LongTensor) -> str:\n",
        "        char_ids = char_ids_tensor.cpu().detach().tolist()\n",
        "\n",
        "        out = []\n",
        "        buf = []\n",
        "        for c in char_ids:\n",
        "            if c < 256:\n",
        "                buf.append(c)\n",
        "            else:\n",
        "                if buf:\n",
        "                    out.append(bytes(buf).decode())\n",
        "                    buf = []\n",
        "                if c == self.start_idx:\n",
        "                    out.append(self.start_token)\n",
        "                elif c == self.end_idx:\n",
        "                    out.append(self.end_token)\n",
        "                elif c == self.pad_idx:\n",
        "                    out.append(self.pad_token)\n",
        "\n",
        "        if buf:  # in case some are left\n",
        "            out.append(bytes(buf).decode())\n",
        "        return \"\".join(out)\n",
        "\n",
        "    def __len__(self):\n",
        "        return 259"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjRndYj5nU_n"
      },
      "source": [
        "class NewsClassification(Dataset):\n",
        "    def __init__(self , df): # df with the news description and label \n",
        "        self.labels = df['Class Index']\n",
        "        self.data = df['Description']\n",
        "        self.encoder = CharByteEncoder()\n",
        "        self.processed = self.process_samples()\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "      return self.processed[i]\n",
        "    \n",
        "    def process_samples(self):\n",
        "      processed = []\n",
        "      for d, l in zip(self.data, self.labels):\n",
        "        processed.append((self.encoder(d.strip()), torch.tensor(l).long()))\n",
        "      return processed\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "      \n",
        "\n",
        "VOCAB_SIZE = 256 + 3  # 256 alternatives in one byte, plus 3 special characters."
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDRY3r-1mOn6"
      },
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def padded_collate(batch, padding_idx=0):\n",
        "\n",
        "    # (xx, yy) = zip(*batch)\n",
        "    # x_lens = [len(x) for x in xx]\n",
        "    # y_lens = [len(y) for y in yy]\n",
        "\n",
        "    # xx_pad = pad_sequence(xx, batch_first=True, padding_value=0)\n",
        "    # yy_pad = pad_sequence(yy, batch_first=True, padding_value=0)\n",
        "\n",
        "    # return xx_pad, yy_pad, x_lens, y_lens\n",
        "    x = pad_sequence([elem[0] for elem in batch], batch_first=True, padding_value=padding_idx)\n",
        "    y = torch.stack([elem[1] for elem in batch]).long()\n",
        "    return x, y"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr1h53Mnn373"
      },
      "source": [
        "secure_rng = False\n",
        "generator = None \n",
        "train_split = 0.8\n",
        "test_every = 5\n",
        "batch_size = 64"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP8Dnme-o3Gg"
      },
      "source": [
        "ds = NewsClassification(df)\n",
        "train_len = int(train_split * len(ds))\n",
        "test_len = len(ds) - train_len"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivHpf4jho6e0",
        "outputId": "395d381b-0c7c-4b85-a5f7-53e84011664f"
      },
      "source": [
        "print(f\"{train_len} samples for training, {test_len} for testing\")"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1920 samples for training, 480 for testing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wl2U3IWfQR0K"
      },
      "source": [
        "train_ds, test_ds = torch.utils.data.random_split(ds, [train_len, test_len], generator=None)"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFtXV3HxoDIG"
      },
      "source": [
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "sample_rate = batch_size / len(train_ds)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    num_workers=1,\n",
        "    pin_memory=True,\n",
        "    generator=generator,\n",
        "    batch_sampler=UniformWithReplacementSampler(\n",
        "        num_samples=len(train_ds),\n",
        "        sample_rate=sample_rate,\n",
        "        generator=generator,\n",
        "    ),\n",
        "    collate_fn=padded_collate,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_ds,\n",
        "    batch_size=2 * batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=1,\n",
        "    pin_memory=True,\n",
        "    collate_fn=padded_collate,\n",
        ")"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJoUY5YloZVM"
      },
      "source": [
        "from opacus.layers import DPLSTM\n",
        "\n",
        "class CharNNClassifier(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_size,\n",
        "        hidden_size,\n",
        "        output_size,\n",
        "        num_lstm_layers=1,\n",
        "        bidirectional=False,\n",
        "        vocab_size=VOCAB_SIZE,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
        "        self.lstm = DPLSTM(\n",
        "            embedding_size,\n",
        "            hidden_size,\n",
        "            num_layers=num_lstm_layers,\n",
        "            bidirectional=bidirectional,\n",
        "            batch_first=True,\n",
        "        )\n",
        "        self.out_layer = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        x = self.embedding(x)  # -> [B, T, D]\n",
        "        x, _ = self.lstm(x, hidden)  # -> [B, T, H]\n",
        "        x = x[:, -1, :]  # -> [B, H]\n",
        "        x = self.out_layer(x)  # -> [B, C]\n",
        "        return x"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB6ygvmdob5i"
      },
      "source": [
        "# Set the device to run on a GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define classifier parameters\n",
        "embedding_size = 64\n",
        "hidden_size = 128  # Number of neurons in hidden layer after LSTM\n",
        "n_lstm_layers = 1\n",
        "bidirectional_lstm = False\n",
        "\n",
        "model = CharNNClassifier(\n",
        "    embedding_size,\n",
        "    hidden_size,\n",
        "    len(ds.labels),\n",
        "    n_lstm_layers,\n",
        "    bidirectional_lstm,\n",
        ").to(device)"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyoTeBGXoQDz"
      },
      "source": [
        "# Training hyper-parameters\n",
        "epochs = 20\n",
        "learning_rate = 2.0\n",
        "\n",
        "# Privacy engine hyper-parameters\n",
        "max_per_sample_grad_norm = 1.5\n",
        "delta = 8e-5\n",
        "epsilon = 12.0"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1O860IioeJm"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8usVx9Bof_b",
        "outputId": "865d6764-d73a-4f85-e148-26374be74038"
      },
      "source": [
        "from opacus import PrivacyEngine\n",
        "\n",
        "privacy_engine = PrivacyEngine(\n",
        "    model,\n",
        "    sample_rate=sample_rate,\n",
        "    max_grad_norm=max_per_sample_grad_norm,\n",
        "    target_delta=delta,\n",
        "    target_epsilon=epsilon,\n",
        "    epochs=epochs,\n",
        "    secure_rng=secure_rng,\n",
        ")\n",
        "privacy_engine.attach(optimizer)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:523: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:195: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmQGndUIoN7f"
      },
      "source": [
        "from statistics import mean\n",
        "\n",
        "def train(model, criterion, optimizer, train_loader, epoch, device=\"cuda:0\"):\n",
        "    accs = []\n",
        "    losses = []\n",
        "    counter = 0 \n",
        "    for x, y in tqdm(train_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        preds = logits.argmax(-1)\n",
        "        n_correct = float(preds.eq(y).sum())\n",
        "        batch_accuracy = n_correct / len(y)\n",
        "\n",
        "        accs.append(batch_accuracy)\n",
        "        losses.append(float(loss))\n",
        "\n",
        "        print('Tensor Shape', (np.shape(x)[0], np.shape(y)[0]))\n",
        "        # counter += 1 \n",
        "        # printstr = (f\"\\t Epoch {epoch}. Batch Failed\")\n",
        "    \n",
        "    printstr = (f\"\\t Epoch {epoch}. Accuracy: {mean(accs):.6f} | Loss: {mean(losses):.6f}\")\n",
        "        \n",
        "    try:\n",
        "        privacy_engine = optimizer.privacy_engine\n",
        "        epsilon, best_alpha = privacy_engine.get_privacy_spent()\n",
        "        printstr += f\" | (ε = {epsilon:.2f}, δ = {privacy_engine.target_delta}) for α = {best_alpha}\"\n",
        "    except :\n",
        "        pass\n",
        "\n",
        "    print(printstr)\n",
        "    return counter \n",
        "\n",
        "\n",
        "def test(model, test_loader, privacy_engine, device=\"cuda:0\"):\n",
        "    accs = []\n",
        "    with torch.no_grad():\n",
        "        for x, y in tqdm(test_loader):\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            preds = model(x).argmax(-1)\n",
        "            n_correct = float(preds.eq(y).sum())\n",
        "            batch_accuracy = n_correct / len(y)\n",
        "\n",
        "            accs.append(batch_accuracy)\n",
        "    printstr = \"\\n----------------------------\\n\" f\"Test Accuracy: {mean(accs):.6f}\"\n",
        "    if privacy_engine:\n",
        "        epsilon, best_alpha = privacy_engine.get_privacy_spent()\n",
        "        printstr += f\" (ε = {epsilon:.2f}, δ = {privacy_engine.target_delta}) for α = {best_alpha}\"\n",
        "    print(printstr + \"\\n----------------------------\\n\")\n",
        "    return"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df6me13noiu8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9e67b3c0-b6af-4434-f4dc-2284088ed121"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "print(\"Train stats: \\n\")\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    train(model, criterion, optimizer, train_loader, epoch, device=device)\n",
        "    if test_every:\n",
        "        if epoch % test_every == 0:  test(model, test_loader, privacy_engine, device=device)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train stats: \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  3%|▎         | 1/30 [00:01<00:39,  1.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape (65, 65)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  7%|▋         | 2/30 [00:02<00:38,  1.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape (59, 59)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 10%|█         | 3/30 [00:04<00:40,  1.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape (70, 70)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 13%|█▎        | 4/30 [00:06<00:40,  1.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape (87, 87)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 17%|█▋        | 5/30 [00:07<00:33,  1.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape (63, 63)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 20%|██        | 6/30 [00:08<00:33,  1.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape (62, 62)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 23%|██▎       | 7/30 [00:09<00:31,  1.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape (63, 63)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 27%|██▋       | 8/30 [00:10<00:25,  1.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape (63, 63)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 30%|███       | 9/30 [00:11<00:21,  1.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape (41, 41)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 33%|███▎      | 10/30 [00:13<00:24,  1.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape (76, 76)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 37%|███▋      | 11/30 [00:14<00:25,  1.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape (78, 78)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 40%|████      | 12/30 [00:16<00:26,  1.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape (64, 64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 43%|████▎     | 13/30 [00:17<00:23,  1.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape (64, 64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 47%|████▋     | 14/30 [00:18<00:21,  1.37s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape (55, 55)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 50%|█████     | 15/30 [00:20<00:21,  1.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape (66, 66)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 53%|█████▎    | 16/30 [00:21<00:19,  1.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape (61, 61)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 57%|█████▋    | 17/30 [00:23<00:17,  1.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape (48, 48)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 60%|██████    | 18/30 [00:23<00:14,  1.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape (58, 58)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 63%|██████▎   | 19/30 [00:25<00:14,  1.28s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape (78, 78)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 67%|██████▋   | 20/30 [00:26<00:13,  1.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape (66, 66)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 70%|███████   | 21/30 [00:27<00:10,  1.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape (57, 57)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 73%|███████▎  | 22/30 [00:29<00:10,  1.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape (77, 77)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 77%|███████▋  | 23/30 [00:30<00:08,  1.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape (50, 50)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 80%|████████  | 24/30 [00:30<00:06,  1.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape (68, 68)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 83%|████████▎ | 25/30 [00:31<00:05,  1.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape (71, 71)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 87%|████████▋ | 26/30 [00:33<00:04,  1.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape (67, 67)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 90%|█████████ | 27/30 [00:34<00:03,  1.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape (59, 59)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 28/30 [00:35<00:02,  1.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape (69, 69)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 29/30 [00:37<00:01,  1.25s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape (68, 68)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 30/30 [00:38<00:00,  1.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape (65, 65)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Epoch 0. Accuracy: 0.310868 | Loss: 2.615948 | (ε = 4.54, δ = 8e-05) for α = 3.6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 25%|██▌       | 1/4 [00:00<00:00,  3.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 50%|█████     | 2/4 [00:00<00:00,  3.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 75%|███████▌  | 3/4 [00:00<00:00,  3.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.82it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  5%|▌         | 1/20 [00:40<12:42, 40.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "----------------------------\n",
            "Test Accuracy: 0.263021 (ε = 4.54, δ = 8e-05) for α = 3.6\n",
            "----------------------------\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/30 [00:00<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-120-aeebe2e33343>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train stats: \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtest_every\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtest_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprivacy_engine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-119-bf380606475e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, train_loader, epoch, device)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py\u001b[0m in \u001b[0;36mdp_step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdp_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprivacy_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \"\"\"\n\u001b[1;32m    358\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclipper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_and_accumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0mclip_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclipper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/opacus/per_sample_gradient_clip.py\u001b[0m in \u001b[0;36mclip_and_accumulate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m         all_norms = calc_sample_norms(\n\u001b[1;32m    179\u001b[0m             \u001b[0mnamed_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_named_grad_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mflat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_clipper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_per_layer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         )\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/opacus/utils/tensor_utils.py\u001b[0m in \u001b[0;36mcalc_sample_norms\u001b[0;34m(named_params, flat)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# calc norm over all layer norms if flat = True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mnorms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnorms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [58] at entry 0 and [128] at entry 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5niPe2hCVm0o"
      },
      "source": [
        "for idx, tup in enumerate(train_loader):\n",
        "  print(tup)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjmQiihO7mwn"
      },
      "source": [
        "test(model, test_loader, privacy_engine, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-ZEfKWq6qDv",
        "outputId": "3c156ba2-4160-4d4a-b75d-fb89e389913b"
      },
      "source": [
        "print(counter)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfQNSKGHD8GL"
      },
      "source": [
        "model_nodp = CharNNClassifier(\n",
        "    embedding_size,\n",
        "    hidden_size,\n",
        "    len(ds.labels),\n",
        "    n_lstm_layers,\n",
        "    bidirectional_lstm,\n",
        ").to(device)\n",
        "\n",
        "\n",
        "optimizer_nodp = torch.optim.SGD(model_nodp.parameters(), lr=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJ2_mG8AEpPM"
      },
      "source": [
        "for epoch in tqdm(range(epochs)):\n",
        "    train(model_nodp, criterion, optimizer_nodp, train_loader, epoch, device=device)\n",
        "    if test_every:\n",
        "        if epoch % test_every == 0:\n",
        "            test(model_nodp, test_loader, None, device=device)\n",
        "\n",
        "test(model_nodp, test_loader, None, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQylIydtKJ8g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}